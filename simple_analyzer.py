#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∞–ø—á —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ OCR.
Fallback –≤–∞—Ä–∏–∞–Ω—Ç –µ—Å–ª–∏ multimodal –º–æ–¥–µ–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç.
"""

from pathlib import Path
from datetime import datetime
import json


def analyze_with_ocr(image_path):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–ø—á—É —Å –ø–æ–º–æ—â—å—é OCR"""
    try:
        import easyocr
        import logging
        print("üìñ –ò—Å–ø–æ–ª—å–∑—É–µ–º EasyOCR –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
        
        # –ü–æ–¥–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è EasyOCR –æ CPU
        logging.getLogger('easyocr.easyocr').setLevel(logging.ERROR)
        
        # –°–æ–∑–¥–∞–µ–º reader (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
        reader = easyocr.Reader(['ru', 'en'], gpu=False, verbose=False)  # –¢–∏—Ö–∏–π —Ä–µ–∂–∏–º
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        results = reader.readtext(str(image_path))
        
        if not results:
            return "OCR –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∫–∞–ø—á–∏."
        
        # –°–æ—Å—Ç–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        text_analysis = "–ê–ù–ê–õ–ò–ó –ö–ê–ü–ß–ò –° –ü–û–ú–û–©–¨–Æ OCR\n"
        text_analysis += "="*40 + "\n\n"
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤ –ø–æ–ª–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
        all_text = " ".join([result[1] for result in results])
        
        text_analysis += "–ù–ê–ô–î–ï–ù–ù–´–ï –¢–ï–ö–°–¢–û–í–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:\n"
        for i, (bbox, text, confidence) in enumerate(results, 1):
            text_analysis += f"{i}. {text} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})\n"
        
        text_analysis += f"\n–ü–û–õ–ù–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n"
        # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
        clean_instruction = all_text.replace(" :", "").replace(": ", " ").strip()
        text_analysis += f'"{clean_instruction}"\n\n'
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–¥–∞–Ω–∏—è
        all_text_lower = all_text.lower()
        
        if any(word in all_text_lower for word in ["–≤—ã–±–µ—Ä–∏—Ç–µ", "select", "click", "–∫–ª–∏–∫–Ω–∏—Ç–µ", "–Ω–∞–π–¥–∏—Ç–µ"]):
            task_type = "–ó–∞–¥–∞–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤"
        elif any(word in all_text_lower for word in ["–≤–≤–µ–¥–∏—Ç–µ", "enter", "type", "–Ω–∞–ø–∏—à–∏—Ç–µ"]):
            task_type = "–¢–µ–∫—Å—Ç–æ–≤–∞—è –∫–∞–ø—á–∞"
        elif any(word in all_text_lower for word in ["–∞–≤—Ç–æ–º–æ–±–∏–ª–∏", "cars", "—Å–≤–µ—Ç–æ—Ñ–æ—Ä—ã", "traffic", "–º–æ—Å—Ç—ã", "bridges"]):
            task_type = "–í–∏–∑—É–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤"
        else:
            task_type = "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä"
        
        text_analysis += f"–ü–†–ï–î–ü–û–õ–ê–ì–ê–ï–ú–´–ô –¢–ò–ü –ó–ê–î–ê–ù–ò–Ø: {task_type}\n\n"
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        text_analysis += "–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –†–ï–®–ï–ù–ò–Ø:\n"
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        if any(word in all_text_lower for word in ["–ª–µ—Å", "forest", "–¥–µ—Ä–µ–≤—å—è", "trees"]):
            text_analysis += "–ß–¢–û –ò–°–ö–ê–¢–¨ (–ª–µ—Å–Ω—ã–µ –ø—Ä–µ–¥–º–µ—Ç—ã):\n"
            text_analysis += "- üå≤ –î–µ—Ä–µ–≤—å—è, –≤–µ—Ç–∫–∏, –ª–∏—Å—Ç—å—è, –∫–æ—Ä–∞\n"
            text_analysis += "- üçÑ –ì—Ä–∏–±—ã, —è–≥–æ–¥—ã, –æ—Ä–µ—Ö–∏, —à–∏—à–∫–∏\n" 
            text_analysis += "- ü¶å –õ–µ—Å–Ω—ã–µ –∂–∏–≤–æ—Ç–Ω—ã–µ (–æ–ª–µ–Ω–∏, –º–µ–¥–≤–µ–¥–∏, –±–µ–ª–∫–∏, –ø—Ç–∏—Ü—ã)\n"
            text_analysis += "- ü™® –ö–∞–º–Ω–∏, –ø–Ω–∏, –º–æ—Ö, –ø–∞–ø–æ—Ä–æ—Ç–Ω–∏–∫–∏\n"
            text_analysis += "- üèïÔ∏è –ö–æ—Å—Ç—Ä—ã, –ø–∞–ª–∞—Ç–∫–∏ (–µ—Å–ª–∏ –≤ –ª–µ—Å—É)\n\n"
            text_analysis += "–î–ï–ô–°–¢–í–ò–ï: –ö–ª–∏–∫–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —ç—Ç–∏–º–∏ –ø—Ä–µ–¥–º–µ—Ç–∞–º–∏\n"
            text_analysis += "‚ùå –ï—Å–ª–∏ –ù–ï–¢ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ‚Üí –Ω–∞–∂–º–∏—Ç–µ '–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å'\n"
            
        elif any(word in all_text_lower for word in ["–∞–≤—Ç–æ–º–æ–±–∏–ª–∏", "cars", "–º–∞—à–∏–Ω—ã"]):
            text_analysis += "- –ò—â–∏—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏, –º–∞—à–∏–Ω—ã, –≥—Ä—É–∑–æ–≤–∏–∫–∏, –º–æ—Ç–æ—Ü–∏–∫–ª—ã\n"
            text_analysis += "- –í–∫–ª—é—á–∞–π—Ç–µ –≤—Å–µ –≤–∏–¥—ã —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤\n"
            text_analysis += "- –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ –≤—Å–µ —è—á–µ–π–∫–∏ —Å —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–æ–º\n"
            
        elif any(word in all_text_lower for word in ["—Å–≤–µ—Ç–æ—Ñ–æ—Ä—ã", "traffic"]):
            text_analysis += "- –ò—â–∏—Ç–µ —Å–≤–µ—Ç–æ—Ñ–æ—Ä—ã –∏ –¥–æ—Ä–æ–∂–Ω—ã–µ –∑–Ω–∞–∫–∏\n" 
            text_analysis += "- –í–∫–ª—é—á–∞–π—Ç–µ —Å—Ç–æ–ª–±—ã —Å–æ —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞–º–∏\n"
            text_analysis += "- –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ –≤—Å–µ —è—á–µ–π–∫–∏ —Å–æ —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞–º–∏\n"
            
        elif any(word in all_text_lower for word in ["—Å–∏–¥–µ—Ç—å", "—Å—Ç—É–ª—å—è", "chairs"]):
            text_analysis += "- –ò—â–∏—Ç–µ —Å—Ç—É–ª—å—è, –∫—Ä–µ—Å–ª–∞, –¥–∏–≤–∞–Ω—ã, —Å–∫–∞–º–µ–π–∫–∏\n"
            text_analysis += "- –í–∫–ª—é—á–∞–π—Ç–µ –ª—é–±—ã–µ –ø—Ä–µ–¥–º–µ—Ç—ã –¥–ª—è —Å–∏–¥–µ–Ω–∏—è\n"
            text_analysis += "- –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ –≤—Å–µ —è—á–µ–π–∫–∏ —Å –º–µ–±–µ–ª—å—é –¥–ª—è —Å–∏–¥–µ–Ω–∏—è\n"
            
        else:
            text_analysis += "- –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –≤—ã—à–µ\n"
            text_analysis += "- –ù–∞–π–¥–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–ø–∏—Å–∞–Ω–∏—é\n"
            text_analysis += "- –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —è—á–µ–π–∫–∏\n"
            text_analysis += "- –ï—Å–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–µ—Ç ‚Üí –Ω–∞–∂–º–∏—Ç–µ '–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å'\n"
        
        return text_analysis
        
    except ImportError:
        return "EasyOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install easyocr"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ OCR –∞–Ω–∞–ª–∏–∑–∞: {e}"


def save_simple_analysis(image_path, analysis_result):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑"""
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ—à–µ–Ω–∏–π
        solutions_path = Path("solutions")
        solutions_path.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        analysis_data = {
            "timestamp": timestamp,
            "image_path": str(image_path),
            "analysis": analysis_result,
            "method": "OCR_fallback"
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª—ã
        json_path = solutions_path / "analysis.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        txt_path = solutions_path / "solution.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(f"–ê–ù–ê–õ–ò–ó –ö–ê–ü–ß–ò (OCR –†–ï–ñ–ò–ú)\n")
            f.write(f"{'='*50}\n")
            f.write(f"–í—Ä–µ–º—è: {timestamp}\n")
            f.write(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}\n")
            f.write(f"{'='*50}\n\n")
            f.write(analysis_result)
        
        print(f"üíæ OCR –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω:")
        print(f"   üìã JSON: {json_path}")
        print(f"   üìÑ TXT:  {txt_path}")
        
        return str(txt_path)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        return None


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) != 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python simple_analyzer.py <–ø—É—Ç—å_–∫_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é>")
        sys.exit(1)
        
    image_path = sys.argv[1]
    
    if not Path(image_path).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")
        sys.exit(1)
        
    print(f"üîç –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∫–∞–ø—á–∏: {image_path}")
    result = analyze_with_ocr(image_path)
    
    if result:
        solution_path = save_simple_analysis(image_path, result)
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç: {solution_path}")
    else:
        print("‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è")
